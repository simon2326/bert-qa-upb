{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2fed881",
   "metadata": {},
   "source": [
    "# **BERT-QA REGLAMENTO UPB**\n",
    "\n",
    "Entregable #3 de la materia **Analítica de Datos No Estructurados / Minería Multimedia**.\n",
    "\n",
    "El objetivo es hacer el fine-tunning de un modelo **BERT en español** para responder preguntas sobre el reglamento estudiantil de la UPB a partir de un dataset .json.\n",
    "\n",
    "> Simón Correa Marín"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4590b44",
   "metadata": {},
   "source": [
    "### **Librerías y configuración**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27fa1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f682882e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de PyTorch: 2.9.1\n",
      "CUDA disponible: False\n",
      "MPS disponible: True\n",
      "Usando MPS (GPU Apple Silicon)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Versión de PyTorch:\", torch.__version__)\n",
    "print(\"CUDA disponible:\", torch.cuda.is_available())\n",
    "print(\"MPS disponible:\", torch.backends.mps.is_available())\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Usando MPS (GPU Apple Silicon)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Usando GPU CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Usando CPU\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f617076",
   "metadata": {},
   "source": [
    "### **Carga de datos desde la URL - Reglamento UPB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc148768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de questions en el dataset: 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>item_id</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Para ingresar a la Universidad Pontificia Boli...</td>\n",
       "      <td>¿Qué se necesita para ingresar a un programa d...</td>\n",
       "      <td>diligenciar y pagar el formulario de inscripción</td>\n",
       "      <td>7b2e6743-75ea-472e-9330-f87a8942d28b</td>\n",
       "      <td>73</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El ingreso a la Universidad puede hacerse como...</td>\n",
       "      <td>¿Cuáles son las formas de ingreso a la UPB?</td>\n",
       "      <td>como estudiante nuevo, por transferencia inter...</td>\n",
       "      <td>9ccbd0aa-aa32-49d1-b15c-adec3b7b7333</td>\n",
       "      <td>42</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los estudiantes extranjeros deben cumplir con ...</td>\n",
       "      <td>¿Qué deben hacer los aspirantes extranjeros pa...</td>\n",
       "      <td>cumplir con los requisitos migratorios exigido...</td>\n",
       "      <td>1aedf782-75f4-4ab3-93cc-fa66235f9be3</td>\n",
       "      <td>34</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Un estudiante nuevo es aquel que es aceptado p...</td>\n",
       "      <td>¿Quién se considera estudiante nuevo en la UPB?</td>\n",
       "      <td>aquel que es aceptado por primera vez en un pr...</td>\n",
       "      <td>857e420b-ae46-49a0-b811-c9121cb91c58</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El reintegro es el proceso mediante el cual un...</td>\n",
       "      <td>¿Qué es el reintegro en la UPB?</td>\n",
       "      <td>el proceso mediante el cual un estudiante que ...</td>\n",
       "      <td>ff7f430f-319e-4ba9-9464-ae5efc54b317</td>\n",
       "      <td>16</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Para ingresar a la Universidad Pontificia Boli...   \n",
       "1  El ingreso a la Universidad puede hacerse como...   \n",
       "2  Los estudiantes extranjeros deben cumplir con ...   \n",
       "3  Un estudiante nuevo es aquel que es aceptado p...   \n",
       "4  El reintegro es el proceso mediante el cual un...   \n",
       "\n",
       "                                            question  \\\n",
       "0  ¿Qué se necesita para ingresar a un programa d...   \n",
       "1        ¿Cuáles son las formas de ingreso a la UPB?   \n",
       "2  ¿Qué deben hacer los aspirantes extranjeros pa...   \n",
       "3    ¿Quién se considera estudiante nuevo en la UPB?   \n",
       "4                    ¿Qué es el reintegro en la UPB?   \n",
       "\n",
       "                                              answer  \\\n",
       "0   diligenciar y pagar el formulario de inscripción   \n",
       "1  como estudiante nuevo, por transferencia inter...   \n",
       "2  cumplir con los requisitos migratorios exigido...   \n",
       "3  aquel que es aceptado por primera vez en un pr...   \n",
       "4  el proceso mediante el cual un estudiante que ...   \n",
       "\n",
       "                                item_id  answer_start  answer_end  \n",
       "0  7b2e6743-75ea-472e-9330-f87a8942d28b            73         121  \n",
       "1  9ccbd0aa-aa32-49d1-b15c-adec3b7b7333            42         133  \n",
       "2  1aedf782-75f4-4ab3-93cc-fa66235f9be3            34         103  \n",
       "3  857e420b-ae46-49a0-b811-c9121cb91c58            23         112  \n",
       "4  ff7f430f-319e-4ba9-9464-ae5efc54b317            16         103  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://robertohincapie.com/data/faq_reglamento_upb_completo_final.json\"\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # lanza error si algo falla\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "print(\"Número de questions en el dataset:\", len(data))\n",
    "\n",
    "# Dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3be9ed",
   "metadata": {},
   "source": [
    "### **Exploración del dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db1fe8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas del dataset: ['context', 'question', 'answer', 'item_id', 'answer_start', 'answer_end']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57 entries, 0 to 56\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   context       57 non-null     object\n",
      " 1   question      57 non-null     object\n",
      " 2   answer        57 non-null     object\n",
      " 3   item_id       57 non-null     object\n",
      " 4   answer_start  57 non-null     int64 \n",
      " 5   answer_end    57 non-null     int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 2.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Columnas del dataset:\", df.columns.tolist())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbe659c",
   "metadata": {},
   "source": [
    "### **División de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe53369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 45\n",
      "Valid: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answer', 'item_id', 'answer_start', 'answer_end'],\n",
       "        num_rows: 45\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'question', 'answer', 'item_id', 'answer_start', 'answer_end'],\n",
       "        num_rows: 12\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train:\", len(train_df))\n",
    "print(\"Valid:\", len(valid_df))\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "valid_ds = Dataset.from_pandas(valid_df.reset_index(drop=True))\n",
    "\n",
    "raw_datasets = DatasetDict({\n",
    "    \"train\": train_ds,\n",
    "    \"validation\": valid_ds,\n",
    "})\n",
    "\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7139757",
   "metadata": {},
   "source": [
    "### **Columna Answers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e90969c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83f1641ac784db3b3f3772741f9a9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349b561f2df34e23a75b9252da663726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context': 'Para obtener el título académico el estudiante debe culminar el plan de estudios, demostrar competencia en segunda lengua, y estar a paz y salvo académica, disciplinaria y financieramente. El título se entrega en ceremonia oficial y puede ser revocado si se demuestra que fue obtenido mediante fraude o falsedad.',\n",
       " 'question': '¿Qué tipo de paz y salvo debe tener?',\n",
       " 'id': 'e8d741df-5cb2-4c71-b9f4-c58b1059d1c6',\n",
       " 'answers': {'answer_start': [145],\n",
       "  'text': ['académica, disciplinaria y financieramente']}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def columna_answers(example):\n",
    "    answer_text = example[\"answer\"]\n",
    "    start_char = example[\"answer_start\"]\n",
    "    return {\n",
    "        \"id\": str(example[\"item_id\"]),\n",
    "        \"context\": example[\"context\"],\n",
    "        \"question\": example[\"question\"],\n",
    "        \"answers\": {\n",
    "            \"text\": [answer_text],\n",
    "            \"answer_start\": [start_char],\n",
    "        },\n",
    "    }\n",
    "\n",
    "df_final = raw_datasets.map(columna_answers)\n",
    "\n",
    "# Columnas necesarias\n",
    "columnas = [\"id\", \"context\", \"question\", \"answers\"]\n",
    "df_final = df_final.remove_columns(\n",
    "    [c for c in df_final[\"train\"].column_names if c not in columnas]\n",
    ")\n",
    "\n",
    "df_final[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d604cb2",
   "metadata": {},
   "source": [
    "## **BERT en Español**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ac506",
   "metadata": {},
   "source": [
    "### **Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d62238a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer cargado desde: dccuchile/bert-base-spanish-wwm-cased\n"
     ]
    }
   ],
   "source": [
    "# Carga del tokenizer BERT en español\n",
    "\n",
    "model_checkpoint = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "print(\"Tokenizer cargado desde:\", model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08124893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021eab3de8ae46708175b4e7dfc3dfb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29243bc0df994c07a9dd9009b389570c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "    num_rows: 45\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparación de features para entrenamiento\n",
    "\n",
    "max_length = 384   # Longitud máxima de secuencia\n",
    "doc_stride = 128   # Solapamiento entre los chunks de contexto\n",
    "\n",
    "def prepare_train_features(examples):\n",
    "    # Limpiamos espacios extra en las preguntas\n",
    "    examples[\"question\"] = [q.strip() for q in examples[\"question\"]]\n",
    "    \n",
    "    tokenized = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        truncation=\"only_second\",          # Truncar únicamente el contexto\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    \n",
    "    sample_mapping = tokenized.pop(\"overflow_to_sample_mapping\")\n",
    "    offset_mapping = tokenized.pop(\"offset_mapping\")\n",
    "    \n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    \n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        input_ids = tokenized[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "        \n",
    "        sample_idx = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_idx]\n",
    "        start_char = answers[\"answer_start\"][0]\n",
    "        end_char = start_char + len(answers[\"text\"][0])\n",
    "        \n",
    "        sequence_ids = tokenized.sequence_ids(i)\n",
    "        \n",
    "        # Índices del contexto dentro de la secuencia de tokens\n",
    "        idx = 0\n",
    "        while idx < len(sequence_ids) and sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        \n",
    "        idx = len(sequence_ids) - 1\n",
    "        while idx >= 0 and sequence_ids[idx] != 1:\n",
    "            idx -= 1\n",
    "        context_end = idx\n",
    "        \n",
    "        # Si la respuesta no cae completamente en este chunk, apuntamos al token CLS\n",
    "        if not (offsets[context_start][0] <= start_char and offsets[context_end][1] >= end_char):\n",
    "            start_positions.append(cls_index)\n",
    "            end_positions.append(cls_index)\n",
    "        else:\n",
    "            # Encontrar token de inicio\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offsets[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_token_index = idx - 1\n",
    "            \n",
    "            # Encontrar token de fin\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offsets[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_token_index = idx + 1\n",
    "            \n",
    "            start_positions.append(start_token_index)\n",
    "            end_positions.append(end_token_index)\n",
    "    \n",
    "    tokenized[\"start_positions\"] = start_positions\n",
    "    tokenized[\"end_positions\"] = end_positions\n",
    "    return tokenized\n",
    "\n",
    "tokenized_train = df_final[\"train\"].map(\n",
    "    prepare_train_features,\n",
    "    batched=True,\n",
    "    remove_columns=df_final[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "tokenized_valid = df_final[\"validation\"].map(\n",
    "    prepare_train_features,\n",
    "    batched=True,\n",
    "    remove_columns=df_final[\"validation\"].column_names,\n",
    ")\n",
    "\n",
    "tokenized_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b6402c",
   "metadata": {},
   "source": [
    "### **Modelo BERT para QA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "774f9992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "model.to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a53ad9f",
   "metadata": {},
   "source": [
    "### **Configuración del Trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72582e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x2/wzyt5ll12z77w4qw_gm51n8w0000gn/T/ipykernel_71106/2393597552.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4 # Se puede bajar a 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"qa-bert-upb-checkpoints\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"loss\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_valid,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a882b57c",
   "metadata": {},
   "source": [
    "### **Entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "248bf73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/Documents/bert-qa-upb/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 37:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.684337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.243272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.237133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/Documents/bert-qa-upb/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/simon/Documents/bert-qa-upb/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=36, training_loss=3.4522357516818576, metrics={'train_runtime': 2243.0137, 'train_samples_per_second': 0.06, 'train_steps_per_second': 0.016, 'total_flos': 26456296619520.0, 'train_loss': 3.4522357516818576, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "train_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463a551c",
   "metadata": {},
   "source": [
    "### **Modelo y tokenizer luego del fine-tunning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e61de13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: /Users/simon/Documents/bert-qa-upb/qa-bert-upb-model\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"qa-bert-upb-model\"\n",
    "\n",
    "model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "print(f\"Modelo guardado en: {os.path.abspath(save_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1c3f7e",
   "metadata": {},
   "source": [
    "## **Inferencia - QA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2181172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.question_answering.QuestionAnsweringPipeline at 0x120ddb890>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "qa_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa38f35",
   "metadata": {},
   "source": [
    "### **Prueba sobre validación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e5b6a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/Documents/bert-qa-upb/.venv/lib/python3.12/site-packages/transformers/pipelines/question_answering.py:395: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Ejemplo 1 =====\n",
      "Pregunta:        ¿Qué se necesita para ingresar a un programa de pregrado en la UPB?\n",
      "Respuesta real:  diligenciar y pagar el formulario de inscripción\n",
      "Respuesta modelo: cumplir con los requisitos de admisión establecidos por la unidad académica\n",
      "Score: 0.011\n",
      "\n",
      "===== Ejemplo 2 =====\n",
      "Pregunta:        ¿Qué debe hacer un estudiante al reintegrarse respecto al plan de estudios?\n",
      "Respuesta real:  acogerse al plan de estudios y tarifas vigentes al momento del retorno\n",
      "Respuesta modelo: acogerse al plan de estudios\n",
      "Score: 0.055\n",
      "\n",
      "===== Ejemplo 3 =====\n",
      "Pregunta:        ¿Cuántas veces puede reservar cupo?\n",
      "Respuesta real:  hasta por dos períodos\n",
      "Respuesta modelo: reserva de cupo\n",
      "Score: 0.026\n",
      "\n",
      "===== Ejemplo 4 =====\n",
      "Pregunta:        ¿Cuál es la nota mínima para aprobar un curso?\n",
      "Respuesta real:  una nota igual o superior a 3.00\n",
      "Respuesta modelo: nota igual o superior a 3.00\n",
      "Score: 0.038\n",
      "\n",
      "===== Ejemplo 5 =====\n",
      "Pregunta:        ¿Qué tipos de evaluación existen?\n",
      "Respuesta real:  formativas y acumulativas\n",
      "Respuesta modelo: nota mínima para aprobar un curso es de 3.00\n",
      "Score: 0.012\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    ejemplo = df_final[\"validation\"][i]\n",
    "    context = ejemplo[\"context\"]\n",
    "    question = ejemplo[\"question\"]\n",
    "    gold_answer = ejemplo[\"answers\"][\"text\"][0]\n",
    "    \n",
    "    pred = qa_pipeline({\n",
    "        \"question\": question,\n",
    "        \"context\": context\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n===== Ejemplo {i+1} =====\")\n",
    "    print(\"Pregunta:       \", question)\n",
    "    print(\"Respuesta real: \", gold_answer)\n",
    "    print(\"Respuesta modelo:\", pred['answer'])\n",
    "    print(\"Score:\", round(pred['score'], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99985f0",
   "metadata": {},
   "source": [
    "### **Prueba manual - Input Usuario**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f9ca53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta del usuario: ¿Cuál es la nota mínima para aprobar un curso en la UPB?\n",
      "Respuesta del modelo: demostrar competencia en segunda lengua\n",
      "Score: 0.056\n"
     ]
    }
   ],
   "source": [
    "# Tomamos un contexto representativo (por simplicidad, uno de los ejemplos)\n",
    "ejemplo_contexto = df_final[\"train\"][0][\"context\"]\n",
    "\n",
    "pregunta_usuario = \"¿Cuál es la nota mínima para aprobar un curso en la UPB?\"\n",
    "\n",
    "pred = qa_pipeline({\n",
    "    \"question\": pregunta_usuario,\n",
    "    \"context\": ejemplo_contexto\n",
    "})\n",
    "\n",
    "print(\"Pregunta del usuario:\", pregunta_usuario)\n",
    "print(\"Respuesta del modelo:\", pred[\"answer\"])\n",
    "print(\"Score:\", round(pred[\"score\"], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346bf0e2",
   "metadata": {},
   "source": [
    "Se debe tener en cuenta que el modelo no conoce todo el reglamento UPB, solo puede extraer una frase del contexto que se le pase, si el contexto no contiene la respuesta, el modelo de igual manera debe escoger alguna respuesta (span de texto) aun así no tenga sentido. Lo que sucedió en este caso es que se le dió un contexto equivocado al modelo. Para evitar esto, se debe buscar un contexto relevante en el dataset antes de llamar al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839663e4",
   "metadata": {},
   "source": [
    "### **Prueba con contexto buscado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89c8b78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>item_id</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Las evaluaciones pueden ser formativas o acumu...</td>\n",
       "      <td>¿Qué tipo de evaluación no requiere nota oblig...</td>\n",
       "      <td>evaluación formativa</td>\n",
       "      <td>66daf9e0-1b2f-4fad-adf1-eefdc56eb90e</td>\n",
       "      <td>58</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Las calificaciones en la UPB se expresan en es...</td>\n",
       "      <td>¿Cuál es la nota mínima para aprobar un curso?</td>\n",
       "      <td>una nota igual o superior a 3.00</td>\n",
       "      <td>76c690e3-8ce1-482e-988b-04ead6ea1115</td>\n",
       "      <td>110</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Las evaluaciones se clasifican en formativas y...</td>\n",
       "      <td>¿Qué tipos de evaluación existen?</td>\n",
       "      <td>formativas y acumulativas</td>\n",
       "      <td>6bf0d797-c0eb-4f32-a1c1-019e7e4e1f53</td>\n",
       "      <td>34</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Las evaluaciones se clasifican en formativas y...</td>\n",
       "      <td>¿Cuál es la nota mínima para aprobar?</td>\n",
       "      <td>3.00</td>\n",
       "      <td>ae7bc4cd-7345-44ad-9919-120b82ddd263</td>\n",
       "      <td>104</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Las evaluaciones se clasifican en formativas y...</td>\n",
       "      <td>¿Qué escala se usa para calificar?</td>\n",
       "      <td>escala de 0.00 a 5.00</td>\n",
       "      <td>d3538c8e-5e81-4015-b9e6-61c67d78e325</td>\n",
       "      <td>143</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              context  \\\n",
       "12  Las evaluaciones pueden ser formativas o acumu...   \n",
       "13  Las calificaciones en la UPB se expresan en es...   \n",
       "34  Las evaluaciones se clasifican en formativas y...   \n",
       "35  Las evaluaciones se clasifican en formativas y...   \n",
       "36  Las evaluaciones se clasifican en formativas y...   \n",
       "\n",
       "                                             question  \\\n",
       "12  ¿Qué tipo de evaluación no requiere nota oblig...   \n",
       "13     ¿Cuál es la nota mínima para aprobar un curso?   \n",
       "34                  ¿Qué tipos de evaluación existen?   \n",
       "35              ¿Cuál es la nota mínima para aprobar?   \n",
       "36                 ¿Qué escala se usa para calificar?   \n",
       "\n",
       "                              answer                               item_id  \\\n",
       "12              evaluación formativa  66daf9e0-1b2f-4fad-adf1-eefdc56eb90e   \n",
       "13  una nota igual o superior a 3.00  76c690e3-8ce1-482e-988b-04ead6ea1115   \n",
       "34         formativas y acumulativas  6bf0d797-c0eb-4f32-a1c1-019e7e4e1f53   \n",
       "35                              3.00  ae7bc4cd-7345-44ad-9919-120b82ddd263   \n",
       "36             escala de 0.00 a 5.00  d3538c8e-5e81-4015-b9e6-61c67d78e325   \n",
       "\n",
       "    answer_start  answer_end  \n",
       "12            58          78  \n",
       "13           110         142  \n",
       "34            34          59  \n",
       "35           104         108  \n",
       "36           143         164  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contextos que hablen de \"nota mínima\" o \"nota igual o superior a 3.00\"\n",
    "mask = df[\"context\"].str.contains(\"nota mínima\", case=False, na=False) | \\\n",
    "       df[\"context\"].str.contains(\"curso\", case=False, na=False)\n",
    "\n",
    "df[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfe211d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/Documents/bert-qa-upb/.venv/lib/python3.12/site-packages/transformers/pipelines/question_answering.py:395: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta del usuario: ¿Cuál es la nota mínima para aprobar un curso en la UPB?\n",
      "Respuesta del modelo: nota igual o superior a 3.00\n",
      "Score: 0.037\n"
     ]
    }
   ],
   "source": [
    "contexto_nota = df[mask].iloc[1][\"context\"]\n",
    "\n",
    "pregunta_usuario = \"¿Cuál es la nota mínima para aprobar un curso en la UPB?\"\n",
    "\n",
    "pred = qa_pipeline({\n",
    "    \"question\": pregunta_usuario,\n",
    "    \"context\": contexto_nota\n",
    "})\n",
    "\n",
    "print(\"Pregunta del usuario:\", pregunta_usuario)\n",
    "print(\"Respuesta del modelo:\", pred[\"answer\"])\n",
    "print(\"Score:\", round(pred[\"score\"], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fa30c4",
   "metadata": {},
   "source": [
    "En un sistema real, este modelo se integraría con un módulo de recuperación de documentos (IR), encargándose BERT únicamente de extraer la respuesta del fragmento más relevante."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
